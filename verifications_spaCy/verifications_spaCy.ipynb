{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifications: spaCy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target: To perform parsing and entity recognition using spaCy\n",
    "- Keywords: Tokenization, POS tagging, Dependency analysis, Words similarity measurement, Entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parsing (分かち書きとPOSタギング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = u\"We are living in Singapore.\\nIt's blazing outside today!\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('We', 561228191312463089, 13656873538139661788, 94)\n",
      "('are', 10382539506755952630, 9188597074677201817, 99)\n",
      "('living', 13874798850131827181, 1534113631682161808, 99)\n",
      "('in', 3002984154512732771, 1292078113972184607, 84)\n",
      "('Singapore', 10329536245932617809, 15794550382381185553, 95)\n",
      "('.', 12646065887601541794, 12646065887601541794, 96)\n",
      "('\\n', '\\n', 0, 102)\n",
      "('It', 561228191312463089, 13656873538139661788, 94)\n",
      "(\"'s\", 10382539506755952630, 13927759927860985106, 99)\n",
      "('blazing', 14126656987735467782, 1534113631682161808, 99)\n",
      "('outside', 12341974070768608367, 164681854541413346, 85)\n",
      "('today', 11042482332948150395, 15308085513773655218, 91)\n",
      "('!', 17494803046312582752, 12646065887601541794, 96)\n",
      "('\\n', '\\n', 0, 102)\n"
     ]
    }
   ],
   "source": [
    "# 各トークンに対しPOSタグのIDを得る\n",
    "for token in doc:\n",
    "    print((token.text, token.lemma, token.tag, token.pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('We', '-PRON-', 'PRP', 'PRON')\n",
      "('are', 'be', 'VBP', 'VERB')\n",
      "('living', 'live', 'VBG', 'VERB')\n",
      "('in', 'in', 'IN', 'ADP')\n",
      "('Singapore', 'singapore', 'NNP', 'PROPN')\n",
      "('.', '.', '.', 'PUNCT')\n",
      "('\\n', '\\n', '', 'SPACE')\n",
      "('It', '-PRON-', 'PRP', 'PRON')\n",
      "(\"'s\", 'be', 'VBZ', 'VERB')\n",
      "('blazing', 'blaze', 'VBG', 'VERB')\n",
      "('outside', 'outside', 'RB', 'ADV')\n",
      "('today', 'today', 'NN', 'NOUN')\n",
      "('!', '!', '.', 'PUNCT')\n",
      "('\\n', '\\n', '', 'SPACE')\n"
     ]
    }
   ],
   "source": [
    "# 各トークンに対しPOSタグを得る\n",
    "for token in doc:\n",
    "    print((token.text, token.lemma_, token.tag_, token.pos_)) # lemma means *root form*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag, POStag　一覧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"c-table o-block\"><tr class=\"c-table__row\"><th class=\"c-table__head-cell u-text-label\">Tag</th><th class=\"c-table__head-cell u-text-label\">POS</th><th class=\"c-table__head-cell u-text-label\">Morphology</th></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>-LRB-</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=brck</code> <code>PunctSide=ini</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>-PRB-</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=brck</code> <code>PunctSide=fin</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>,</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=comm</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>:</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>.</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=peri</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>''</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=quot</code> <code>PunctSide=fin</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>&quot;&quot;</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=quot</code> <code>PunctSide=fin</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>#</code></td><td class=\"c-table__cell u-text\"> <code>SYM</code></td><td class=\"c-table__cell u-text\"> <code>SymType=numbersign</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>``</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=quot</code> <code>PunctSide=ini</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code></code></td><td class=\"c-table__cell u-text\"> <code>SYM</code></td><td class=\"c-table__cell u-text\"> <code>SymType=currency</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>ADD</code></td><td class=\"c-table__cell u-text\"> <code>X</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>AFX</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>Hyph=yes</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>BES</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>CC</code></td><td class=\"c-table__cell u-text\"> <code>CONJ</code></td><td class=\"c-table__cell u-text\"> <code>ConjType=coor</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>CD</code></td><td class=\"c-table__cell u-text\"> <code>NUM</code></td><td class=\"c-table__cell u-text\"> <code>NumType=card</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>DT</code></td><td class=\"c-table__cell u-text\"> <code>DET</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>EX</code></td><td class=\"c-table__cell u-text\"> <code>ADV</code></td><td class=\"c-table__cell u-text\"> <code>AdvType=ex</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>FW</code></td><td class=\"c-table__cell u-text\"> <code>X</code></td><td class=\"c-table__cell u-text\"> <code>Foreign=yes</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>GW</code></td><td class=\"c-table__cell u-text\"> <code>X</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>HVS</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>HYPH</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>PunctType=dash</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>IN</code></td><td class=\"c-table__cell u-text\"> <code>ADP</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>JJ</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>Degree=pos</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>JJR</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>Degree=comp</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>JJS</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>Degree=sup</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>LS</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"> <code>NumType=ord</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>MD</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"> <code>VerbType=mod</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>NFP</code></td><td class=\"c-table__cell u-text\"> <code>PUNCT</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>NIL</code></td><td class=\"c-table__cell u-text\"></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>NN</code></td><td class=\"c-table__cell u-text\"> <code>NOUN</code></td><td class=\"c-table__cell u-text\"> <code>Number=sing</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>NNP</code></td><td class=\"c-table__cell u-text\"> <code>PROPN</code></td><td class=\"c-table__cell u-text\"> <code>NounType=prop</code> <code>Number=sign</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>NNPS</code></td><td class=\"c-table__cell u-text\"> <code>PROPN</code></td><td class=\"c-table__cell u-text\"> <code>NounType=prop</code> <code>Number=plur</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>NNS</code></td><td class=\"c-table__cell u-text\"> <code>NOUN</code></td><td class=\"c-table__cell u-text\"> <code>Number=plur</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>PDT</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>AdjType=pdt</code> <code>PronType=prn</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>POS</code></td><td class=\"c-table__cell u-text\"> <code>PART</code></td><td class=\"c-table__cell u-text\"> <code>Poss=yes</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>PRP</code></td><td class=\"c-table__cell u-text\"> <code>PRON</code></td><td class=\"c-table__cell u-text\"> <code>PronType=prs</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>PRP</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>PronType=prs</code> <code>Poss=yes</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>RB</code></td><td class=\"c-table__cell u-text\"> <code>ADV</code></td><td class=\"c-table__cell u-text\"> <code>Degree=pos</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>RBR</code></td><td class=\"c-table__cell u-text\"> <code>ADV</code></td><td class=\"c-table__cell u-text\"> <code>Degree=comp</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>RBS</code></td><td class=\"c-table__cell u-text\"> <code>ADV</code></td><td class=\"c-table__cell u-text\"> <code>Degree=sup</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>RP</code></td><td class=\"c-table__cell u-text\"> <code>PART</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>SP</code></td><td class=\"c-table__cell u-text\"> <code>SPACE</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>SYM</code></td><td class=\"c-table__cell u-text\"> <code>SYM</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>TO</code></td><td class=\"c-table__cell u-text\"> <code>PART</code></td><td class=\"c-table__cell u-text\"> <code>PartType=inf</code> <code>VerbForm=inf</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>UH</code></td><td class=\"c-table__cell u-text\"> <code>INTJ</code></td><td class=\"c-table__cell u-text\"></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>VB</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"> <code>VerbForm=inf</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>VBD</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"> <code>VerbForm=fin</code> <code>Tense=past</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>VBG</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"> <code>VerbForm=part</code> <code>Tense=pres</code> <code>Aspect=prog</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>VBN</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"> <code>VerbForm=part</code> <code>Tense=past</code> <code>Aspect=perf</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>VBP</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"> <code>VerbForm=fin</code> <code>Tense=pres</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>VBZ</code></td><td class=\"c-table__cell u-text\"> <code>VERB</code></td><td class=\"c-table__cell u-text\"> <code>VerbForm=fin</code> <code>Tense=pres</code> <code>Number=sing</code> <code>Person=3</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>WDT</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>PronType=int|rel</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>WP</code></td><td class=\"c-table__cell u-text\"> <code>NOUN</code></td><td class=\"c-table__cell u-text\"> <code>PronType=int|rel</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>WP</code></td><td class=\"c-table__cell u-text\"> <code>ADJ</code></td><td class=\"c-table__cell u-text\"> <code>Poss=yes</code> <code>PronType=int|rel</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>WRB</code></td><td class=\"c-table__cell u-text\"> <code>ADV</code></td><td class=\"c-table__cell u-text\"> <code>PronType=int|rel</code></td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"> <code>XX</code></td><td class=\"c-table__cell u-text\"> <code>X</code></td><td class=\"c-table__cell u-text\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タグの定義一覧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table cellpadding=\"2\" cellspacing=\"2\" border=\"0\">\n",
    "  <tr bgcolor=\"#DFDFFF\" align=\"none\"> \n",
    "    <td align=\"none\"> \n",
    "      <div align=\"left\">Number</div>\n",
    "    </td>\n",
    "    <td> \n",
    "      <div align=\"left\">Tag</div>\n",
    "    </td>\n",
    "    <td> \n",
    "      <div align=\"left\">Description</div>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 1. </td>\n",
    "    <td>CC </td>\n",
    "    <td>Coordinating conjunction </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 2. </td>\n",
    "    <td>CD </td>\n",
    "    <td>Cardinal number </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 3. </td>\n",
    "    <td>DT </td>\n",
    "    <td>Determiner </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 4. </td>\n",
    "    <td>EX </td>\n",
    "    <td>Existential <i>there<i> </i></i></td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 5. </td>\n",
    "    <td>FW </td>\n",
    "    <td>Foreign word </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 6. </td>\n",
    "    <td>IN </td>\n",
    "    <td>Preposition or subordinating conjunction </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 7. </td>\n",
    "    <td>JJ </td>\n",
    "    <td>Adjective </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 8. </td>\n",
    "    <td>JJR </td>\n",
    "    <td>Adjective, comparative </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 9. </td>\n",
    "    <td>JJS </td>\n",
    "    <td>Adjective, superlative </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 10. </td>\n",
    "    <td>LS </td>\n",
    "    <td>List item marker </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 11. </td>\n",
    "    <td>MD </td>\n",
    "    <td>Modal </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 12. </td>\n",
    "    <td>NN </td>\n",
    "    <td>Noun, singular or mass </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 13. </td>\n",
    "    <td>NNS </td>\n",
    "    <td>Noun, plural </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 14. </td>\n",
    "    <td>NNP </td>\n",
    "    <td>Proper noun, singular </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 15. </td>\n",
    "    <td>NNPS </td>\n",
    "    <td>Proper noun, plural </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 16. </td>\n",
    "    <td>PDT </td>\n",
    "    <td>Predeterminer </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 17. </td>\n",
    "    <td>POS </td>\n",
    "    <td>Possessive ending </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 18. </td>\n",
    "    <td>PRP </td>\n",
    "    <td>Personal pronoun </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 19. </td>\n",
    "    <td>PRP </td>\n",
    "    <td>Possessive pronoun </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 20. </td>\n",
    "    <td>RB </td>\n",
    "    <td>Adverb </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 21. </td>\n",
    "    <td>RBR </td>\n",
    "    <td>Adverb, comparative </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 22. </td>\n",
    "    <td>RBS </td>\n",
    "    <td>Adverb, superlative </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 23. </td>\n",
    "    <td>RP </td>\n",
    "    <td>Particle </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 24. </td>\n",
    "    <td>SYM </td>\n",
    "    <td>Symbol </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 25. </td>\n",
    "    <td>TO </td>\n",
    "    <td><i>to</i> </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 26. </td>\n",
    "    <td>UH </td>\n",
    "    <td>Interjection </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 27. </td>\n",
    "    <td>VB </td>\n",
    "    <td>Verb, base form </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 28. </td>\n",
    "    <td>VBD </td>\n",
    "    <td>Verb, past tense </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 29. </td>\n",
    "    <td>VBG </td>\n",
    "    <td>Verb, gerund or present participle </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 30. </td>\n",
    "    <td>VBN </td>\n",
    "    <td>Verb, past participle </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 31. </td>\n",
    "    <td>VBP </td>\n",
    "    <td>Verb, non-3rd person singular present </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 32. </td>\n",
    "    <td>VBZ </td>\n",
    "    <td>Verb, 3rd person singular present </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 33. </td>\n",
    "    <td>WDT </td>\n",
    "    <td>Wh-determiner </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 34. </td>\n",
    "    <td>WP </td>\n",
    "    <td>Wh-pronoun </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 35. </td>\n",
    "    <td>WP </td>\n",
    "    <td>Possessive wh-pronoun </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FFFFCA\"> \n",
    "    <td align=\"none\"> 36. </td>\n",
    "    <td>WRB </td>\n",
    "    <td>Wh-adverb \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各トークンについて得られるその他の情報\n",
    "ここでは主語Sakamotoを例にとってその他情報の主要なものを表示してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: Sakamoto\n",
      "vocab (The vocab object of the parent Doc): <spacy.vocab.Vocab object at 0x10f48bf48>\n",
      "doc (The parent document.): Mr.Sakamoto told us the Dragon Fruits was very yummy!\n",
      "i (The index of the token within the parent document.): 2\n",
      "ent_type_ (Named entity type.): \n",
      "ent_iob_ (IOB code of named entity tag): O\n",
      "ent_id_ (ID of the entity the token is an instance of): \n",
      "lemma_ (Base form of the word, with no inflectional suffixes.): sakamoto\n",
      "lower_ (Lower-case form of the word.): sakamoto\n",
      "shape_ (A transform of the word's string, to show orthographic features.): Xxxxx\n",
      "prefix_ (Integer ID of a length-N substring from the start of the word): S\n",
      "suffix_ (Length-N substring from the end of the word): oto\n",
      "like_url (Does the word resemble a URL?): False\n",
      "like_num (Does the word represent a number? ): False\n",
      "like_email (Does the word resemble an email address?): False\n",
      "is_oov (Is the word out-of-vocabulary?): True\n",
      "is_stop (Is the word part of a stop list?): False\n",
      "pos_ (Coarse-grained part-of-speech.): PROPN\n",
      "tag_ (Fine-grained part-of-speech.): NNP\n",
      "dep_ (Syntactic dependency relation.): nsubj\n",
      "lang_ (Language of the parent document's vocabulary.): en\n",
      "prob: (Smoothed log probability estimate of token's type.) -20.0\n",
      "idx (The character offset of the token within the parent document.): 3\n",
      "sentiment (A scalar value indicating the positivity or negativity of the token): 0.0\n",
      "lex_id (ID of the token's lexical type.): 0\n",
      "text (Verbatim text content.): Sakamoto\n",
      "text_with_ws (Text content, with trailing space character if present.): Sakamoto \n",
      "whitespace_ (Trailing space character if present.):  \n"
     ]
    }
   ],
   "source": [
    "#https://spacy.io/docs/api/token\n",
    "doc_ps = nlp(\"Mr.Sakamoto told us the Dragon Fruits was very yummy!\") \n",
    "#for t in doc:\n",
    "t = doc_ps[2]\n",
    "print(\"token:\",t)\n",
    "print(\"vocab (The vocab object of the parent Doc):\", t.vocab)\n",
    "print(\"doc (The parent document.):\", t.doc)\n",
    "print(\"i (The index of the token within the parent document.):\", t.i)\n",
    "print(\"ent_type_ (Named entity type.):\", t.ent_type_)\n",
    "print(\"ent_iob_ (IOB code of named entity tag):\", t.ent_iob_)\n",
    "print(\"ent_id_ (ID of the entity the token is an instance of):\", t.ent_id_)\n",
    "print(\"lemma_ (Base form of the word, with no inflectional suffixes.):\", t.lemma_)\n",
    "print(\"lower_ (Lower-case form of the word.):\", t.lower_)\n",
    "print(\"shape_ (A transform of the word's string, to show orthographic features.):\", t.shape_)\n",
    "print(\"prefix_ (Integer ID of a length-N substring from the start of the word):\", t.prefix_)\n",
    "print(\"suffix_ (Length-N substring from the end of the word):\", t.suffix_)\n",
    "print(\"like_url (Does the word resemble a URL?):\", t.like_url)\n",
    "print(\"like_num (Does the word represent a number? ):\", t.like_num)\n",
    "print(\"like_email (Does the word resemble an email address?):\", t.like_email)\n",
    "print(\"is_oov (Is the word out-of-vocabulary?):\", t.is_oov)\n",
    "print(\"is_stop (Is the word part of a stop list?):\", t.is_stop)\n",
    "print(\"pos_ (Coarse-grained part-of-speech.):\", t.pos_)\n",
    "print(\"tag_ (Fine-grained part-of-speech.):\", t.tag_)\n",
    "print(\"dep_ (Syntactic dependency relation.):\", t.dep_)\n",
    "print(\"lang_ (Language of the parent document's vocabulary.):\", t.lang_)\n",
    "print(\"prob: (Smoothed log probability estimate of token's type.)\", t.prob)\n",
    "print(\"idx (The character offset of the token within the parent document.):\", t.idx)\n",
    "print(\"sentiment (A scalar value indicating the positivity or negativity of the token):\", t.sentiment)\n",
    "print(\"lex_id (ID of the token's lexical type.):\", t.lex_id)\n",
    "print(\"text (Verbatim text content.):\", t.text)\n",
    "print(\"text_with_ws (Text content, with trailing space character if present.):\", t.text_with_ws)\n",
    "print(\"whitespace_ (Trailing space character if present.):\", t.whitespace_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 係り受け解析\n",
    "spaCyの係り受け解析を行いビジュアライゼーションするためのデモサイトが存在する  \n",
    "displaCy (https://demos.explosion.ai/displacy/)  \n",
    "<br>\n",
    "例えば、'I like chicken rice and Laksa.'という文章に対し、次のような描画が行われる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/spacy_dependency01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは同様な係り受け解析をテキストベースで行ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'I', 'nsubj', 'like')\n",
      "('chicken rice', 'rice', 'dobj', 'like')\n",
      "('Laksa', 'Laksa', 'conj', 'rice')\n"
     ]
    }
   ],
   "source": [
    "# 各名詞について、root.dep_が役割・関係を、root.head.textが係り受け元を表す\n",
    "doc_dep = nlp(u'I like chicken rice and Laksa.')\n",
    "for np in doc_dep.noun_chunks:\n",
    "    print((np.text, np.root.text, np.root.dep_, np.root.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP', 'nsubj', 0, 0, 'like', [], []),\n",
      " ('like', 'VBP', 'ROOT', 1, 2, 'like', ['I'], ['rice', '.']),\n",
      " ('chicken', 'NN', 'compound', 0, 0, 'rice', [], []),\n",
      " ('rice', 'NN', 'dobj', 1, 2, 'like', ['chicken'], ['and', 'Laksa']),\n",
      " ('and', 'CC', 'cc', 0, 0, 'rice', [], []),\n",
      " ('Laksa', 'NNP', 'conj', 0, 0, 'rice', [], []),\n",
      " ('.', '.', 'punct', 0, 0, 'like', [], [])]\n"
     ]
    }
   ],
   "source": [
    "#名詞以外の全トークンについても、役割・関係を表示することが可能\n",
    "doc_dep_list = []\n",
    "for token in doc_dep:\n",
    "    doc_dep_list.append((token.text, token.tag_, token.dep_, token.n_lefts, token.n_rights, token.head.orth_, [t.orth_ for t in token.lefts], [t.orth_ for t in token.rights]))\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(doc_dep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>n_lefts</th>\n",
       "      <th>n_rights</th>\n",
       "      <th>head.orth_</th>\n",
       "      <th>orth_ in token.lefts</th>\n",
       "      <th>orth_ in token.rights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>like</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like</td>\n",
       "      <td>VBP</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>like</td>\n",
       "      <td>[I]</td>\n",
       "      <td>[rice, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicken</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rice</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rice</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>like</td>\n",
       "      <td>[chicken]</td>\n",
       "      <td>[and, Laksa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rice</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laksa</td>\n",
       "      <td>NNP</td>\n",
       "      <td>conj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rice</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>like</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text tag_      dep_  n_lefts  n_rights head.orth_ orth_ in token.lefts  \\\n",
       "0        I  PRP     nsubj        0         0       like                   []   \n",
       "1     like  VBP      ROOT        1         2       like                  [I]   \n",
       "2  chicken   NN  compound        0         0       rice                   []   \n",
       "3     rice   NN      dobj        1         2       like            [chicken]   \n",
       "4      and   CC        cc        0         0       rice                   []   \n",
       "5    Laksa  NNP      conj        0         0       rice                   []   \n",
       "6        .    .     punct        0         0       like                   []   \n",
       "\n",
       "  orth_ in token.rights  \n",
       "0                    []  \n",
       "1             [rice, .]  \n",
       "2                    []  \n",
       "3          [and, Laksa]  \n",
       "4                    []  \n",
       "5                    []  \n",
       "6                    []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandasのテーブルで表示してみる\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(doc_dep_list)\n",
    "df.columns = ['text','tag_','dep_','n_lefts','n_rights','head.orth_','orth_ in token.lefts','orth_ in token.rights']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 矢印を使って関係を図示してみる\n",
    "dependency_pattern = '{left}<---{word}[{w_type}]--->{right}\\n--------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]<---I[nsubj]--->[]\n",
      "--------\n",
      "['I']<---like[ROOT]--->['rice', '.']\n",
      "--------\n",
      "[]<---chicken[compound]--->[]\n",
      "--------\n",
      "['chicken']<---rice[dobj]--->['and', 'Laksa']\n",
      "--------\n",
      "[]<---and[cc]--->[]\n",
      "--------\n",
      "[]<---Laksa[conj]--->[]\n",
      "--------\n",
      "[]<---.[punct]--->[]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for token in doc_dep:\n",
    "    print (dependency_pattern.format(word=token.orth_, \n",
    "                                  w_type=token.dep_,\n",
    "                                  left=[t.orth_ for t in token.lefts],\n",
    "                                  right=[t.orth_ for t in token.rights]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word Vecorを用いた単語の類似度取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Vector (small size)の読み込み\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Singapore', 'Singapore', 1.0]\n",
      "['Singapore', 'Japan', 0.69249845]\n",
      "['Singapore', 'Tokyo', 0.48649472]\n",
      "['Japan', 'Singapore', 0.69249845]\n",
      "['Japan', 'Japan', 1.0000001]\n",
      "['Japan', 'Tokyo', 0.57047987]\n",
      "['Tokyo', 'Singapore', 0.48649472]\n",
      "['Tokyo', 'Japan', 0.57047987]\n",
      "['Tokyo', 'Tokyo', 1.0]\n",
      "[[1.0, 0.69249845, 0.48649472], [0.69249845, 1.0000001, 0.57047987], [0.48649472, 0.57047987, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'Singapore Japan Tokyo')\n",
    "similarities = []\n",
    "for token1 in tokens:\n",
    "    sim_row = []\n",
    "    for token2 in tokens:\n",
    "        print([token1.text, token2.text, token1.similarity(token2)])\n",
    "        sim_row.append(token1.similarity(token2))\n",
    "    similarities.append(sim_row)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singapore</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Tokyo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Singapore</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692498</td>\n",
       "      <td>0.486495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>0.692498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokyo</th>\n",
       "      <td>0.486495</td>\n",
       "      <td>0.570480</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Singapore     Japan     Tokyo\n",
       "Singapore   1.000000  0.692498  0.486495\n",
       "Japan       0.692498  1.000000  0.570480\n",
       "Tokyo       0.486495  0.570480  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(similarities)\n",
    "df.columns = tokens\n",
    "df.index=tokens\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.エンティティ認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NTUC', 'ORG')\n",
      "('has', '(not an entity)')\n",
      "('raised', '(not an entity)')\n",
      "('S$25', 'CARDINAL')\n",
      "('million', 'CARDINAL')\n",
      "('to', '(not an entity)')\n",
      "('help', '(not an entity)')\n",
      "('workers', '(not an entity)')\n",
      "('re', '(not an entity)')\n",
      "('-', '(not an entity)')\n",
      "('skill', '(not an entity)')\n",
      "('and', '(not an entity)')\n",
      "('upgrade', '(not an entity)')\n",
      "('their', '(not an entity)')\n",
      "('skills', '(not an entity)')\n",
      "(',', '(not an entity)')\n",
      "('secretary', '(not an entity)')\n",
      "('-', '(not an entity)')\n",
      "('general', '(not an entity)')\n",
      "('Chan', 'PERSON')\n",
      "('Chun', 'PERSON')\n",
      "('Sing', 'PERSON')\n",
      "('said', '(not an entity)')\n",
      "('at', '(not an entity)')\n",
      "('the', 'DATE')\n",
      "('May', 'DATE')\n",
      "('Day', 'DATE')\n",
      "('Rally', 'DATE')\n",
      "('on', 'DATE')\n",
      "('Monday', 'DATE')\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"NTUC has raised S$25 million to help workers re-skill and upgrade their skills, secretary-general Chan Chun Sing said at the May Day Rally on Monday \"\n",
    "parsed = nlp(example_sent)\n",
    "for token in parsed:\n",
    "    print((token.orth_, token.ent_type_ if token.ent_type_ != \"\" else \"(not an entity)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Visualization using displaCy Named Entity Visualizer (https://demos.explosion.ai/displacy-ent/)\n",
    "<img src=\"../img/spacy_ner01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エンティティタイプ一覧 \n",
    "https://spacy.io/docs/usage/entity-recognition\n",
    "\n",
    "<table class=\"c-table o-block\"><tr class=\"c-table__row\"><th class=\"c-table__head-cell u-text-label\">Type</th><th class=\"c-table__head-cell u-text-label\">Description</th></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>PERSON</code></td><td class=\"c-table__cell u-text\">People, including fictional.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>NORP</code></td><td class=\"c-table__cell u-text\">Nationalities or religious or political groups.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>FACILITY</code></td><td class=\"c-table__cell u-text\">Buildings, airports, highways, bridges, etc.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>ORG</code></td><td class=\"c-table__cell u-text\">Companies, agencies, institutions, etc.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>GPE</code></td><td class=\"c-table__cell u-text\">Countries, cities, states.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>LOC</code></td><td class=\"c-table__cell u-text\">Non-GPE locations, mountain ranges, bodies of water.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>PRODUCT</code></td><td class=\"c-table__cell u-text\">Objects, vehicles, foods, etc. (Not services.)</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>EVENT</code></td><td class=\"c-table__cell u-text\">Named hurricanes, battles, wars, sports events, etc.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>WORK_OF_ART</code></td><td class=\"c-table__cell u-text\">Titles of books, songs, etc.</td></tr><tr class=\"c-table__row\"><td class=\"c-table__cell u-text\"><code>LANGUAGE</code></td><td class=\"c-table__cell u-text\">Any named language.</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エンティティ認識モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ\n",
    "TRAIN_DATA = [\n",
    "    ('Who is Daphne Khoo?', {'entities': [(7, 18, 'PERSON')]}),\n",
    "    ('I like Bangkok and Buangkok.', {'entities': [(7, 14, 'LOC'), (19, 27, 'LOC')]})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "# モデルの読み込み\n",
    "nlp = spacy.blank('en')  # create blank Language class\n",
    "print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインの生成\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "# otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データのラベルをパイプラインnerに追加\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 13.175836280376352}\n",
      "{'ner': 12.667925622750635}\n",
      "{'ner': 9.95857561635717}\n",
      "{'ner': 6.250982132274663}\n",
      "{'ner': 10.797445607903985}\n",
      "{'ner': 6.29055441384935}\n",
      "{'ner': 8.415489806663096}\n",
      "{'ner': 8.65286132128112}\n",
      "{'ner': 7.9207013388083904}\n",
      "{'ner': 5.176604208581704}\n",
      "{'ner': 2.0163456532285933}\n",
      "{'ner': 1.6894788717259888}\n",
      "{'ner': 0.0035130279810733087}\n",
      "{'ner': 1.0005834656321062}\n",
      "{'ner': 3.4471729101848494}\n",
      "{'ner': 3.0742444012545636}\n",
      "{'ner': 1.8941273111148758}\n",
      "{'ner': 3.0038413572032066}\n",
      "{'ner': 1.3641084270238104}\n",
      "{'ner': 2.0024618038231115}\n",
      "{'ner': 1.8680192646406215}\n",
      "{'ner': 3.708134078557032}\n",
      "{'ner': 3.9812688870266085e-05}\n",
      "{'ner': 1.9123445341356675}\n",
      "{'ner': 5.623626587195949e-09}\n",
      "{'ner': 0.171074504659794}\n",
      "{'ner': 4.9556581891946755e-05}\n",
      "{'ner': 0.00027758975395631433}\n",
      "{'ner': 0.6852870714143676}\n",
      "{'ner': 7.23222076358214e-16}\n",
      "{'ner': 1.581942049117866e-08}\n",
      "{'ner': 0.08680034869202281}\n",
      "{'ner': 0.655540899188921}\n",
      "{'ner': 2.4608986337185897e-08}\n",
      "{'ner': 1.5703130161498047e-18}\n",
      "{'ner': 1.1917643547058105}\n",
      "{'ner': 2.970459469725457e-08}\n",
      "{'ner': 3.801232039357835e-05}\n",
      "{'ner': 1.79201504297957e-07}\n",
      "{'ner': 8.297489102926664e-06}\n",
      "{'ner': 2.458438029304095e-10}\n",
      "{'ner': 5.036494797774968e-13}\n",
      "{'ner': 9.446496617153243e-17}\n",
      "{'ner': 1.9999170778653188}\n",
      "{'ner': 6.840049043408974e-15}\n",
      "{'ner': 6.411619861283276e-10}\n",
      "{'ner': 8.353323527348175e-09}\n",
      "{'ner': 1.0691307424161867e-17}\n",
      "{'ner': 6.9233122901271816e-18}\n",
      "{'ner': 4.3082183689669477e-10}\n",
      "{'ner': 3.375853877217081e-14}\n",
      "{'ner': 2.0582996871645627e-10}\n",
      "{'ner': 1.889222713681738e-21}\n",
      "{'ner': 0.0027531427332088717}\n",
      "{'ner': 6.916357609773975e-21}\n",
      "{'ner': 2.5359814003592824e-09}\n",
      "{'ner': 1.6719424383527515e-22}\n",
      "{'ner': 8.239658426913596e-11}\n",
      "{'ner': 1.0174172820640428e-18}\n",
      "{'ner': 2.4655708836547853e-15}\n",
      "{'ner': 4.343578014869356e-12}\n",
      "{'ner': 5.774127342752554e-12}\n",
      "{'ner': 3.903129577187322e-19}\n",
      "{'ner': 3.579160081673204e-14}\n",
      "{'ner': 2.2611803049788942e-17}\n",
      "{'ner': 1.2504093316323722e-09}\n",
      "{'ner': 1.782820404566854e-17}\n",
      "{'ner': 2.2721923857991093e-15}\n",
      "{'ner': 1.7100553767232922e-22}\n",
      "{'ner': 3.156257591424202e-10}\n",
      "{'ner': 1.9843262269006047e-10}\n",
      "{'ner': 1.0335262648644278e-09}\n",
      "{'ner': 7.794432113948634e-14}\n",
      "{'ner': 2.0633290417769404e-11}\n",
      "{'ner': 1.5982198602920958e-12}\n",
      "{'ner': 0.061873274808784316}\n",
      "{'ner': 0.6776654720316179}\n",
      "{'ner': 4.416180241046207e-15}\n",
      "{'ner': 1.794433949576639e-12}\n",
      "{'ner': 4.328521969297569e-17}\n",
      "{'ner': 0.8291975087340647}\n",
      "{'ner': 3.604514727474612e-13}\n",
      "{'ner': 9.449767718242567e-06}\n",
      "{'ner': 3.1768062668013833e-21}\n",
      "{'ner': 3.6045156162355276e-14}\n",
      "{'ner': 1.0533146519564296e-09}\n",
      "{'ner': 3.252339817328499e-09}\n",
      "{'ner': 4.22827997681452e-06}\n",
      "{'ner': 9.908678818373393e-21}\n",
      "{'ner': 4.4428952892203756e-20}\n",
      "{'ner': 7.195154466899546e-05}\n",
      "{'ner': 1.2933900828698882e-17}\n",
      "{'ner': 2.515984694513044e-22}\n",
      "{'ner': 5.616810274259759e-14}\n",
      "{'ner': 0.6332147717475891}\n",
      "{'ner': 3.405378835661196e-17}\n",
      "{'ner': 5.32069205401071e-18}\n",
      "{'ner': 2.9645957511093e-07}\n",
      "{'ner': 8.32046499263131e-16}\n",
      "{'ner': 1.5083980717146988e-18}\n"
     ]
    }
   ],
   "source": [
    "# 他のパイプラインを一時無効化しながら訓練を開始\n",
    "n_iter=100\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            nlp.update(\n",
    "                [text],  # batch of texts\n",
    "                [annotations],  # batch of annotations\n",
    "                drop=0.5,  # dropout - make it harder to memorise data\n",
    "                sgd=optimizer,  # callable to update weights\n",
    "                losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Daphne Khoo', 'PERSON')]\n",
      "Tokens [('Who', '', 2), ('is', '', 2), ('Daphne', 'PERSON', 3), ('Khoo', 'PERSON', 1), ('?', '', 2)]\n",
      "Entities [('Bangkok', 'LOC'), ('Buangkok', 'LOC')]\n",
      "Tokens [('I', '', 2), ('like', '', 2), ('Bangkok', 'LOC', 3), ('and', '', 2), ('Buangkok', 'LOC', 3), ('.', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to sample_ner\n"
     ]
    }
   ],
   "source": [
    "# outputディレクトリへモデルを保存\n",
    "output_dir = './sample_ner/'\n",
    "output_dir = Path(output_dir)\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sample_ner\n",
      "Entities [('Daphne Khoo', 'PERSON')]\n",
      "Tokens [('Who', '', 2), ('is', '', 2), ('Daphne', 'PERSON', 3), ('Khoo', 'PERSON', 1), ('?', '', 2)]\n",
      "Entities [('Bangkok', 'LOC'), ('Buangkok', 'LOC')]\n",
      "Tokens [('I', '', 2), ('like', '', 2), ('Bangkok', 'LOC', 3), ('and', '', 2), ('Buangkok', 'LOC', 3), ('.', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "# 保存したモデルで再度テスト\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp2(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reference\n",
    "https://spacy.io/<br>\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html<br>\n",
    "https://spacy.io/docs/usage/pos-tagging<br>\n",
    "https://spacy.io/usage/training <br>\n",
    "\n",
    "[Installation]  \n",
    "pip install spacy  \n",
    "python -m spacy download en  \n",
    "python -m spacy download en_core_web_sm\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "243px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
